{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3K5OJSYDOlSOR09COOoQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmcanavals/ml/blob/main/representaciones_de_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF"
      ],
      "metadata": {
        "id": "ZwJgc0T2NgGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Corpus"
      ],
      "metadata": {
        "id": "IyWgoMI8OgBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_yGidQ7NMqp",
        "outputId": "036f5946-efc8-46ad-a7a2-e814c3cdb400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing corpus.txt\n"
          ]
        }
      ],
      "source": [
        "%%file corpus.txt\n",
        "saludo al sol con una sonrisa\n",
        "cuando sonries se te ven los dientes\n",
        "como los dientes de un sol de caricatura"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re"
      ],
      "metadata": {
        "id": "F0uhKuT9SRIJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reoresentaci√≥n binaria"
      ],
      "metadata": {
        "id": "zwFISDCrQdVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"corpus.txt\") as f:\n",
        "    corpus = f.readlines()\n",
        "temp = []\n",
        "for line in corpus:\n",
        "    temp.append(line.split())\n",
        "corpus = temp\n",
        "\n",
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhYmRNN6QU-h",
        "outputId": "6ac4c4bc-2702-4d36-cf48-ad4b88994935"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['saludo', 'al', 'sol', 'con', 'una', 'sonrisa'], ['cuando', 'sonries', 'se', 'te', 'ven', 'los', 'dientes'], ['como', 'los', 'dientes', 'de', 'un', 'sol', 'de', 'caricatura']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordsidx = []\n",
        "for line in corpus:\n",
        "    wordsidx.extend(line)\n",
        "\n",
        "wordsidx = list(set(wordsidx))\n",
        "print(wordsidx)\n",
        "print(len(wordsidx))\n",
        "words = {word: idx for idx, word in enumerate(wordsidx)}\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66RCwmTcQnzx",
        "outputId": "721514d4-5775-473a-dd6d-56de4ee8537c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['se', 'saludo', 'cuando', 'una', 'te', 'ven', 'dientes', 'de', 'los', 'caricatura', 'con', 'al', 'como', 'sol', 'sonrisa', 'un', 'sonries']\n",
            "17\n",
            "{'se': 0, 'saludo': 1, 'cuando': 2, 'una': 3, 'te': 4, 'ven': 5, 'dientes': 6, 'de': 7, 'los': 8, 'caricatura': 9, 'con': 10, 'al': 11, 'como': 12, 'sol': 13, 'sonrisa': 14, 'un': 15, 'sonries': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols, rows = len(wordsidx), len(corpus)\n",
        "dataset = np.zeros((rows, cols), dtype=int)\n",
        "for i, line in enumerate(corpus):\n",
        "    for word in line:\n",
        "        dataset[i, words[word]] = 1\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOJunDiaRIeA",
        "outputId": "4f2c3b13-017a-46be-8a31-78bcfec694c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0]\n",
            " [1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some real data"
      ],
      "metadata": {
        "id": "TtbN2wrt7DQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"https://raw.githubusercontent.com/lmcanavals/ml/main/data/spam.csv\"\n",
        "spamdf = pd.read_csv(url,encoding ='latin1')\n",
        "spamdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_BingxysSp1A",
        "outputId": "d9272318-66b0-4bae-cf6b-20074b8ff9b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     v1                                                 v2 Unnamed: 2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "\n",
              "  Unnamed: 3 Unnamed: 4  \n",
              "0        NaN        NaN  \n",
              "1        NaN        NaN  \n",
              "2        NaN        NaN  \n",
              "3        NaN        NaN  \n",
              "4        NaN        NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e87f4034-339b-4f95-b3f3-d3c94fef650a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e87f4034-339b-4f95-b3f3-d3c94fef650a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e87f4034-339b-4f95-b3f3-d3c94fef650a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e87f4034-339b-4f95-b3f3-d3c94fef650a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = spamdf[\"v2\"][0]\n",
        "print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fajVhYfk9Ix9",
        "outputId": "16ebceb5-da9e-48b2-d3fd-b0adbd347fe4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = WhitespaceTokenizer().tokenize(sentence)\n",
        "print(token)\n",
        "print(sentence.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNLlZdEG-OAV",
        "outputId": "0708abee-5b92-44b4-9666-d2e9cf2dee31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Go', 'until', 'jurong', 'point,', 'crazy..', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet...', 'Cine', 'there', 'got', 'amore', 'wat...']\n",
            "['Go', 'until', 'jurong', 'point,', 'crazy..', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet...', 'Cine', 'there', 'got', 'amore', 'wat...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit WhitespaceTokenizer().tokenize(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AdOtPA4-WGD",
        "outputId": "3993f122-8b82-4c18-998f-4a873ec18587"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.29 ¬µs ¬± 728 ns per loop (mean ¬± std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit sentence.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR-5KEb0-gUk",
        "outputId": "c7d15940-f788-4755-ea1c-739362a4d605"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "526 ns ¬± 11.1 ns per loop (mean ¬± std. dev. of 7 runs, 1000000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordsRE = '[a-zA-Z]+'\n",
        "tokenizer = RegexpTokenizer(wordsRE)\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBJ-rgr3-kVr",
        "outputId": "262728a4-4d6b-4fc4-f7ab-9f73df876d58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Go', 'until', 'jurong', 'point', 'crazy', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'Cine', 'there', 'got', 'amore', 'wat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Econtremos todos los valores monetarios"
      ],
      "metadata": {
        "id": "aeDOckhWBWg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordsRE = '\\$\\d+\\.?\\d+?'\n",
        "tokenizer = RegexpTokenizer(wordsRE)\n",
        "tokens = [ token for e in spamdf[\"v2\"] for token in tokenizer.tokenize(e) ]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c_CdX87Alab",
        "outputId": "1409aa4c-f5f3-4bd2-df4e-b4d82b6ca40b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['$350', '$95', '$50', '$50', '$700', '$900', '$700', '$900', '$5.0', '$5.0', '$140', '$180', '$900']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordsRE = 'S[a-zA-Z]*'\n",
        "tokenizer = RegexpTokenizer(wordsRE)\n",
        "tokens = [ token for e in spamdf[\"v2\"] for token in tokenizer.tokenize(e) ]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVkx2ItgJHQE",
        "outputId": "def583e1-cb9c-4b0e-9adb-0fa227666bc0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SIX', 'SH', 'SH', 'SUNDAY', 'S', 'SCOTLAND', 'So', 'S', 'SG', 'SEEING', 'SMS', 'Sptv', 'SPTV', 'Sherawat', 'Suprman', 'StarWars', 'Sorry', 'Sorry', 'Send', 'S', 'ShrAcomOrSglSuplt', 'S', 'SOMETHING', 'Still', 'Sorry', 'Sorry', 'Sorry', 'Smile', 'Smile', 'Smile', 'Smile', 'Smile', 'SOMEONE', 'Smiling', 'Simply', 'So', 'She', 'So', 'Statement', 'So', 'SUM', 'Sunshine', 'Sony', 'SP', 'Sir', 'Stop', 'Sindu', 'S', 'STOP', 'S', 'See', 'SMS', 'STOP', 'Send', 'STOP', 'SHOULD', 'Service', 'S', 'See', 'Sir', 'S', 'SHA', 'She', 'Sounds', 'Sorry', 'ST', 'S', 'Sorry', 'Sam', 'So', 'SITUATION', 'SON', 'So', 'SSSSSSSEEEEEE', 'SPORTSx', 'SIC', 'Same', 'Stop', 'STOP', 'S', 'SPECIAL', 'Send', 'So', 'STUPID', 'SS', 'SLVYL', 'Shit', 'SMS', 'Sister', 'Swtheart', 'So', 'Special', 'Send', 'So', 'Sorry', 'SUZY', 'Sorry', 'ST', 'SLAP', 'SELF', 'SH', 'S', 'S', 'S', 'Sirji', 'SSCO', 'SIC', 'SH', 'Suite', 'Since', 'S', 'So', 'SonyEricsson', 'Services', 'So', 'Some', 'So', 'Sony', 'So', 'Sir', 'Salam', 'SSCO', 'ST', 'Same', 'Sender', 'Sent', 'Send', 'Someone', 'Siva', 'Send', 'Sentiment', 'She', 'Shoul', 'Sorry', 'SPEOPLE', 'SAY', 'S', 'Sorry', 'Si', 'SO', 'Start', 'Sorry', 'SH', 'SAE', 'Someone', 'So', 'SSAGE', 'Sorry', 'Suprman', 'StarWars', 'Sorry', 'Sorry', 'Some', 'SMS', 'So', 'Silent', 'Spl', 'Stylish', 'Simple', 'S', 'Slide', 'Slow', 'STOP', 'Shall', 'S', 'SavaMob', 'Sub', 'Statement', 'S', 'Subscription', 'Sorry', 'Sure', 'Sunscreen', 'So', 'SSY', 'So', 'SHOP', 'Statement', 'S', 'Speaking', 'SIVE', 'SAISAI', 'SOIREE', 'SPECIALE', 'S', 'S', 'SES', 'S', 'STOP', 'Send', 'S', 'SOON', 'So', 'SURE', 'S', 'S', 'S', 'S', 'S', 'S', 'Search', 'Seventeen', 'STOP', 'Sweetheart', 'Statement', 'S', 'STM', 'SW', 'SS', 'Sometimes', 'Sonetimes', 'Sorry', 'Sorry', 'Sun', 'Sorry', 'Start', 'See', 'SMS', 'STOP', 'Say', 'SUE', 'Sorry', 'Sorry', 'So', 'Save', 'Send', 'S', 'StewartSize', 'Subject', 'Spring', 'START', 'Same', 'Service', 'STOP', 'So', 'Shit', 'S', 'Summer', 'Shopping', 'STORE', 'SkilGme', 'Sorry', 'Schools', 'Silent', 'Spl', 'Stylish', 'Simple', 'She', 'SMS', 'SUBPOLY', 'Sub', 'Sorry', 'S', 'ST', 'SOUNDING', 'S', 'SHOP', 'SavaMob', 'SavaMob', 'Sub', 'S', 'So', 'SIC', 'Shinco', 'SEEMED', 'SPEAK', 'SOONLOTS', 'SMSSERVICES', 'STOP', 'Sorry', 'So', 'STOP', 'STOP', 'Surely', 'Sir', 'S', 'SavaMob', 'Sub', 'STOP', 'SAE', 'SK', 'Sorry', 'S', 'SavaMob', 'Sub', 'SN', 'SE', 'SPK', 'SN', 'S', 'Stop', 'Spoons', 'Sorry', 'Same', 'Statement', 'S', 'Shakespeare', 'SHESIL', 'Shop', 'S', 'Sunshine', 'Sony', 'SP', 'Secret', 'She', 'She', 'Superb', 'Simply', 'Stereophonics', 'Strokes', 'S', 'STORES', 'Sale', 'SLVYL', 'She', 'S', 'So', 'SH', 'SAE', 'SK', 'Since', 'SAE', 'SMS', 'Shb', 'S', 'Sorry', 'SEE', 'So', 'S', 'Should', 'Shall', 'Somebody', 'SHEFFIELD', 'ST', 'SHITIN', 'SELF', 'ST', 'S', 'S', 'STOP', 'STOL', 'ST', 'S', 'S', 'S', 'SNORING', 'SENDS', 'STENDERS', 'See', 'S', 'Someone', 'Send', 'SHIP', 'SiPix', 'Subscriber', 'S', 'S', 'So', 'So', 'SPEEDCHAT', 'SPEEDCHAT', 'SWAP', 'So', 'Sorry', 'She', 'Sender', 'Sent', 'Send', 'Suite', 'STOP', 'Sorry', 'Sorry', 'Something', 'SITUATION', 'SON', 'So', 'Shesil', 'Sex', 'SIC', 'SIM', 'So', 'Sorry', 'ST', 'So', 'Silent', 'Spl', 'Stylish', 'Simple', 'SORRY', 'SORTED', 'S', 'Service', 'SERIOUSLY', 'SE', 'S', 'SPOBox', 'Sorry', 'SAID', 'SHIT', 'Sure', 'So', 'S', 'S', 'S', 'S', 'So', 'Sorry', 'SWER', 'Syria', 'SO', 'Sometimes', 'Sweet', 'She', 'St', 'Soul', 'Sent', 'SMS', 'Shuhui', 'SIES', 'ST', 'Storming', 'She', 'Staying', 'Shall', 'Sinco', 'Sinco', 'SER', 'S', 'S', 'STIC', 'SURPRISE', 'Suite', 'So', 'Speak', 'She', 'SIC', 'S', 'SION', 'S', 'STILL', 'Stupid', 'Summers', 'SUMMER', 'STOP', 'SPOBox', 'Speak', 'SAP', 'SA', 'SMS', 'So', 'Sorry', 'See', 'Smile', 'Sometimes', 'SMS', 'Sco', 'S', 'SCO', 'S', 'SIES', 'SING', 'Sounds', 'Shall', 'Sarcasm', 'Should', 'Suite', 'SHIP', 'SLEEP', 'SWEET', 'S', 'S', 'Shant', 'Single', 'Sux', 'Sister', 'Swtheart', 'Suite', 'SMS', 'Suite', 'So', 'Sounds', 'Sympathetic', 'Stylist', 'Sunday', 'Sorry', 'Something', 'SLVYL', 'Somewhr', 'Statement', 'S', 'Subscriber', 'S', 'S', 'SIMPLE', 'SW', 'SS', 'Sounds', 'Sorry', 'ST', 'SFA', 'STERS', 'ST', 'Shiny', 'S', 'SMS', 'Sleeping', 'SWITCH', 'See', 'S', 'S', 'S', 'So', 'So', 'Sh', 'Send', 'ST', 'SO', 'SORRY', 'SEE', 'SO', 'SUBPOLY', 'Sunshine', 'Sony', 'SP', 'So', 'Sorry', 'Sorry', 'So', 'Sorry', 'Spain', 'S', 'STEAD', 'S', 'Sullivan', 'S', 'SH', 'SATIONS', 'S', 'S', 'SAT', 'Someone', 'Slowly', 'Sorry', 'Sometimes', 'SLVYL', 'START', 'SMS', 'Suite', 'Space', 'See', 'SMS', 'SLVYL', 'So', 'Scared', 'S', 'SS', 'Sian', 'Same', 'Still', 'Sent', 'Squishy', 'See', 'S', 'Starts', 'S', 'Super', 'Sorry', 'Say', 'Send', 'She', 'Sir', 'S', 'SPECIAL', 'Send', 'S', 'Sorry', 'Suite', 'SAE', 'So', 'STEN', 'S', 'STENING', 'STOP', 'Sorry', 'Search', 'Stop', 'S', 'Sol', 'SAE', 'Stockport', 'SK', 'Somebody', 'Said', 'Sweetest', 'Said', 'Speak', 'Send', 'STOP', 'Still', 'Shhhhh', 'Sorry', 'Sorry', 'SAE', 'S', 'Sorry', 'ST', 'S', 'SO', 'SEE', 'Shall', 'SOMETHING', 'SAT', 'S', 'Shopping', 'See', 'SNT', 'SH', 'Speak', 'SkillGame', 'Subscription', 'Speak', 'SS', 'SO', 'Simply', 'So', 'Service', 'Sir', 'Saeed', 'SAP', 'ST', 'SFA', 'STERS', 'ST', 'Sexy', 'Singles', 'Sleepwell', 'SMS', 'STOP', 'S', 'S', 'SavaMob', 'SavaMob', 'Subs', 'Statement', 'SMS', 'SERVICES', 'STOP', 'St', 'Speak', 'Sunshine', 'Starts', 'Saturday', 'Stop', 'SkillGame', 'Subscription', 'SMS', 'Sorry', 'Shijas', 'S', 'SMS', 'Spoke', 'Send', 'Sunshine', 'Starts', 'Saturday', 'Stop', 'So', 'STAPATI', 'S', 'Sad', 'She', 'She', 'She', 'SURPRISE', 'Shop', 'S', 'SE', 'So', 'See', 'SPECIALLY', 'S', 'So', 'S', 'SHIP', 'SAP', 'Sol', 'SAE', 'Stockport', 'SK', 'Should', 'Si', 'She', 'Should', 'Shifad', 'Sad', 'SplashMobile', 'STOP', 'SAM', 'ST', 'Sorry', 'Speak', 'StopTx', 'SSIN', 'SS', 'SMS', 'Suprman', 'StarWars', 'Should', 'Still', 'SIC', 'Street', 'STOP', 'SP', 'Suite', 'So', 'Should', 'Sorry', 'Sorry', 'SAP', 'SonyEricsson', 'Sir', 'Spook', 'SPOOK', 'Sky', 'Sky', 'Scoring', 'Saturday', 'SKY', 'STOP', 'Stream', 'She', 'S', 'SARY', 'SUSUAL', 'S', 'Sir', 'Sorry', 'Someone', 'Scotch', 'Shampain', 'Second', 'Speak', 'SSUP', 'SLO', 'Solve', 'Sir', 'Send', 'Suite', 'SMS', 'SERVICES', 'STOP', 'Special', 'Send', 'She', 'SJESUS', 'Says', 'See', 'Sorry', 'So', 'Suganya', 'S', 'S', 'SavaMob', 'SavaMob', 'Subs', 'Sppok', 'SPOOK', 'SAE', 'Sender', 'SOON', 'SHERS', 'Salary', 'Suman', 'S', 'Should', 'Sorry', 'Sorry', 'Sorry', 'Say', 'Send', 'So', 'She', 'She', 'She', 'Shoranur', 'STOP', 'ST', 'So', 'SG', 'SNAP', 'Stop', 'SP', 'Some', 'She', 'SFREE', 'SFREE', 'Service', 'STOP', 'S', 'Still', 'Sunshine', 'Sony', 'SP', 'Spose', 'So', 'SH', 'S', 'S', 'S', 'ST', 'SAM', 'SE', 'Sir', 'SMS', 'S', 'S', 'SAP', 'SIR', 'Sorry', 'SHA', 'Sorry', 'Sorry', 'Super', 'Sara', 'Shock', 'Smith', 'Switch', 'Solve', 'Sir', 'S', 'SPORT', 'Sept', 'ST', 'Send', 'S', 'S', 'Sorry', 'STOP', 'SAE', 'Sol', 'SH', 'SAE', 'Send', 'Suite', 'Send', 'Sat', 'Say', 'Send', 'SFWC', 'Sept', 'Super', 'Still', 'Send', 'Still', 'St', 'S', 'S', 'Say', 'Send', 'Some', 'SLEEPINGWITH', 'ST', 'Send', 'SH', 'See', 'Sorry', 'Sad', 'She', 'She', 'She', 'SURPRISE', 'SY', 'SHOW', 'She', 'Stop', 'So', 'Smith', 'SY', 'SHOW', 'See', 'STOPBCM', 'SF', 'SHOP', 'SavaMob', 'SavaMob', 'Sub', 'Shuhui', 'SonyEricsson', 'SH', 'SH', 'SEE', 'S', 'SEX', 'Sweet', 'Such', 'Sorry', 'Sorry', 'Sleeping', 'So', 'STOP', 'Sir', 'SDISCOUNT', 'SHITINNIT', 'Sary', 'SonyEricsson', 'SMS', 'Send', 'STOP', 'SIES', 'So', 'Sex', 'STOP', 'SH', 'Speak', 'Stop', 'So', 'Sankranti', 'Shivratri', 'SHING', 'SE', 'Someone', 'Slaaaaave', 'So', 'So', 'Someone', 'She', 'STENDERS', 'SP', 'Sounds', 'So', 'Somebody', 'S', 'So', 'S', 'StdTxtRate', 'STOP', 'Shijas', 'STOP', 'Short', 'Stop', 'Small', 'Sto', 'So', 'So', 'S', 'SG', 'S', 'SGS', 'STOP', 'SHIT', 'SA', 'SSED', 'S', 'SE', 'SAT', 'SOUND', 'S', 'S', 'Sorry', 'STOP', 'SAM', 'SE', 'SED', 'SE', 'SMS', 'Sorry', 'ST', 'SLAP', 'SELF', 'SIES', 'SLVYL', 'Still', 'S', 'SH', 'So', 'SURPRISE', 'S', 'Sleep', 'Summer', 'Shopping', 'STORE', 'SkilGme', 'So', 'She', 'She', 'She', 'SEND', 'STCARD', 'S', 'She', 'Should', 'Sorry', 'Send', 'SIX', 'SH', 'SH', 'Sup', 'Squeeeeeze', 'Sorry', 'S', 'SAP', 'So', 'STARS', 'SMS', 'Sleep', 'Solve', 'Sir', 'SAM', 'S', 'ST', 'S', 'S', 'SO', 'S', 'Someone', 'S', 'SiPix', 'So', 'Sex', 'STOP', 'Said', 'Sweetest', 'Said', 'Stop', 'SSU', 'SO', 'SAY', 'SEND', 'STCARD', 'S', 'S', 'STHERE', 'S', 'SI', 'S', 'Sankatmochan', 'SH', 'S', 'Set', 'S', 'ST', 'ST', 'SOON', 'SSAGE', 'Since', 'She', 'She', 'Sac', 'Send', 'Sorry', 'S', 'STATION', 'Still', 'Sorry', 'Sorry', 'She', 'So', 'Sorry', 'Sorry', 'Sorry', 'So', 'STAR', 'SK', 'SG', 'So', 'Same', 'So', 'Sometimes', 'Sleepwell', 'S', 'STUDENTFINANCIAL', 'SIS', 'SPK', 'S', 'SmartCall', 'Subscriptn', 'Stop', 'Save', 'S', 'Sure', 'STUDY', 'SiPix', 'Sending', 'Save', 'Scotch', 'Shampain', 'Sitting', 'Should', 'Sorry', 'Speak', 'Sat', 'Sun', 'So', 'Still', 'So', 'Strong', 'SIVE', 'S', 'Symbol', 'Still', 'See', 'Staff', 'So', 'She', 'SPUN', 'SPK', 'SLEEPING', 'SOFA', 'Should', 'Sat', 'Sorry', 'So', 'Sprint', 'SO', 'S', 'S', 'S', 'S', 'S', 'S', 'SG', 'Saristar', 'Stop', 'Single', 'Still', 'S', 'Shahjahan', 'Shahjahan', 'S', 'S', 'S', 'Sent', 'She', 'Sends', 'START', 'SLVYL', 'START', 'So', 'Stop', 'So', 'Sorry', 'She', 'S', 'Sorry', 'S', 'S', 'SSAGE', 'SENT', 'Still', 'Should', 'STOP', 'SAME', 'S', 'ST', 'SOO', 'STOP', 'See', 'Sorry', 'Senthil', 'Studying', 'Sorry', 'So', 'See', 'Sweetheart', 'Sexy', 'Sugar', 'Suite', 'So', 'Summer', 'Shopping', 'STORE', 'SkilGme', 'Stupid', 'Sir', 'Speak', 'S', 'Shall', 'SUBPOLY', 'S', 'S', 'Sorry', 'ST', 'Still', 'Should', 'Suite', 'So', 'So', 'She', 'Sounds', 'S', 'SKED', 'Someone', 'S', 'Sir', 'So', 'SHA', 'StoreQuiz', 'Salad', 'S', 'Short', 'Start', 'Sold', 'Same', 'SHESIL', 'Send', 'S', 'S', 'SIC', 'SIB', 'SMS', 'S', 'Sure', 'So', 'So', 'S', 'SS', 'Sky', 'Sky', 'Scoring', 'Saturday', 'SKY', 'SLVYL', 'Single', 'Send', 'STOPCS', 'So', 'SMILEY', 'SUNDAY', 'S', 'S', 'SWEET', 'Sorry', 'She', 'She', 'SLVYL', 'Short', 'Same', 'SonyEricsson', 'STERDAY', 'SH', 'SAE', 'Sounds', 'Serious', 'She', 'She', 'So', 'She', 'Sister', 'Swtheart', 'Sos', 'ST', 'STRIKE', 'S', 'SELFINDEPENDENCE', 'S', 'She', 'Sorry', 'Secured', 'So', 'See', 'SWEET', 'S', 'S', 'Sort', 'So', 'Strong', 'SIVE', 'S', 'Symbol', 'So', 'S', 'SAW', 'SCARY', 'ST', 'S', 'SUMTHIN', 'Sorry', 'S', 'SOON', 'SW', 'SS', 'Sorry', 'SEN', 'Should', 'SLVYL', 'Street', 'STOP', 'SP', 'SavaMob', 'SavaMob', 'SavaMob', 'Student', 'Service', 'S', 'S', 'SOLVO', 'Sept', 'S', 'S', 'Sir', 'Soup', 'STOP', 'Statement', 'S', 'Say', 'SOH', 'SPAM', 'STOP', 'SIES', 'Seem', 'Sorry', 'Something', 'Sure', 'Speak', 'Serena', 'SPJanuary', 'Sale', 'Sorry', 'Stop', 'Simpsons', 'Send', 'Speak', 'Sat', 'Sol', 'SAE', 'Stockport', 'SK', 'Sorry', 'Spanish', 'SAE', 'Sorry', 'Sorry', 'Sony', 'Sorry', 'S', 'STOP', 'SER', 'S', 'S', 'STIC', 'Stupid', 'Spiral', 'SG', 'S', 'STOP', 'SkillGame', 'Subscription', 'Sez', 'Safe', 'Show', 'SS', 'She', 'Space', 'Send', 'S', 'S', 'STIC', 'SURPRISE', 'Sad', 'She', 'SORRY', 'STIL', 'ST', 'S', 'See', 'SMS', 'STOP', 'Send', 'STOP', 'Science', 'Strip', 'S', 'SPECIAL', 'Send', 'Sol', 'SAE', 'Stockport', 'SK', 'STUPID', 'SS', 'SLVYL', 'Someone', 'She', 'So', 'So', 'STU', 'SO', 'S', 'ST', 'SE', 'S', 'Sorry', 'See', 'Snd', 'SO', 'SAID', 'Sorry', 'S', 'STIC', 'SURPRISE', 'Sorry', 'So', 'S', 'S', 'S', 'ST', 'S', 'SURE', 'Smile', 'Stay', 'So', 'So', 'Sat', 'S', 'SG', 'Suite', 'S', 'So', 'Shopping', 'Shola', 'She', 'Sagamu', 'S', 'SE', 'STaND', 'STaY', 'Sorry', 'STOP', 'Sad', 'Still', 'So', 'Sounds', 'S', 'ShrAcomOrSglSuplt', 'S', 'Storming', 'She', 'Sorry', 'Sorry', 'S', 'SOZI', 'S', 'She', 'She', 'Sorry', 'So', 'S', 'SEX', 'Shopping', 'SMS', 'SERVICES', 'STOP', 'So', 'Stupid', 'She', 'Sorry', 'Sure', 'So', 'STOP', 'S', 'School', 'SSED', 'SAD', 'SNT', 'So', 'STOP', 'SS', 'STUPID', 'SLVYL', 'Spoke', 'SYMPTOMS', 'Sun', 'SMS', 'SS', 'S', 'S', 'SOMEONE', 'SE', 'S', 'S', 'S', 'Said', 'Sweetest', 'Said', 'Should', 'Should', 'SCOOL', 'SIC', 'S', 'SAE', 'SK', 'SHOP', 'Secret', 'So', 'STOP', 'See', 'Subscribe', 'Stop', 'Scared', 'Sorry', 'Sunshine', 'Sony', 'Sorry', 'S', 'S', 'SHOWR', 'Sorry', 'SIB', 'SMS', 'S', 'S', 'Statement', 'S', 'SOZ', 'S', 'SP', 'Sry', 'Surly', 'Shijas', 'S', 'STS', 'SH', 'ST', 'SAME', 'S', 'S', 'SMS', 'Shijutta', 'Space', 'See', 'SiPix', 'S', 'S', 'STOP', 'S', 'S', 'SHAME', 'So', 'Sh', 'Sorry', 'ST', 'SEEN', 'Sen', 'SAE', 'SK', 'Send', 'Sorry', 'Saw', 'Swayze', 'STERDAY', 'Santa', 'Santa', 'Should', 'Sorry', 'Statement', 'Second', 'Shah', 'ST', 'ST', 'S', 'Statement', 'S', 'S', 'Same', 'So', 'SSAGE', 'Subscription', 'Service', 'SGRCVD', 'Skip', 'STOP', 'Sorry', 'Shit', 'SO', 'Smiling', 'So', 'S', 'See', 'SMS', 'STOP', 'Send', 'STOP', 'SITUATION', 'SON', 'So', 'Stop', 'Sounds', 'Send', 'SUPER', 'SN', 'S', 'S', 'So', 'SWAT', 'SONY', 'S', 'S', 'STAKE', 'SE', 'SPITAL', 'SORRY', 'Splat', 'Should', 'See', 'Sitting', 'So', 'SEXYCHAT', 'STOP', 'So', 'SH', 'Speak', 'Select', 'She', 'See', 'Stuff', 'S', 'SHIP', 'S', 'Spending', 'So', 'Sorry', 'Slept', 'S', 'See', 'SMS', 'STOP', 'Send', 'STOP', 'So', 'Since', 'SIC', 'SOON', 'Suite', 'Suite', 'Statement', 'S', 'S', 'See', 'SMS', 'STOP', 'Send', 'STOP', 'She', 'Should', 'Service', 'Sorry', 'So', 'Shopping', 'Starting', 'STORE', 'SkilGme', 'Sorry', 'SHIT', 'STFOUND', 'S', 'SELFISH', 'Sorry', 'St', 'Shanil', 'Sorry', 'Sugababes', 'She', 'SS', 'SS', 'SLVYL', 'She', 'Statement', 'SHALL', 'S', 'SE', 'Send', 'Sday', 'Sorry', 'Sol', 'SAE', 'Stockport', 'SK', 'Scotsman', 'Saturday', 'S', 'S', 'S', 'S', 'SI', 'Sir', 'Sweet', 'SMS', 'Sms', 'STOP', 'Sorry', 'Spook', 'SPOOK', 'She', 'Sol', 'SAE', 'Stockport', 'SK', 'STUDENT', 'SCOUNT', 'S', 'Should', 'StopTxt', 'She', 'S', 'See', 'SMS', 'STOP', 'Send', 'STOP', 'SWOKE', 'S', 'SLEPT', 'SPINOUT', 'SSIP', 'Smile', 'Smile', 'Smile', 'Smile', 'Smile', 'SOMEONE', 'Smiling', 'Statement', 'S', 'SEN', 'Started', 'See', 'Silent', 'Spl', 'Stylish', 'Simple', 'Someonone', 'SK', 'SAE', 'Sweet', 'South', 'Storming', 'She', 'S', 'SOMETHIN', 'SWAN', 'SOMETHING', 'S', 'SO', 'Suite', 'So', 'So', 'Sweet', 'Sent', 'SAE', 'S', 'SIC', 'Speak', 'STOP', 'Sir', 'Salam', 'Shop', 'Sweet', 'Sir', 'Sounds', 'So', 'STOP', 'SURPRISE', 'SIMPLE', 'Shall', 'See', 'SiPix', 'S', 'S', 'SSAGE', 'SHIP', 'SLEEP', 'SWEET', 'S', 'SP', 'Somebody', 'Soon', 'S', 'S', 'So', 'So', 'So', 'So', 'Sorry', 'Santa', 'Santa', 'Sar', 'Shall', 'So', 'Sac', 'Sorry', 'Subscribe', 'Stop', 'Shall', 'Scotsman', 'Saturday', 'Spanish', 'STM', 'SW', 'SS', 'Shall', 'So', 'Spider', 'SPIDER', 'So', 'SAP', 'SMS', 'SERVICES', 'STOP', 'Statement', 'S', 'Stupid', 'So', 'So', 'SiPix', 'Statement', 'S', 'She', 'SEX', 'SKED', 'S', 'S', 'ST', 'SERVs', 'SED', 'S', 'SHIT', 'S', 'S', 'So', 'Sorry', 'Sony', 'So']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document labeling"
      ],
      "metadata": {
        "id": "wweOlkN9NRiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming and Lemmatisation"
      ],
      "metadata": {
        "id": "viUgC7EeNVbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "6AP4ocxzLl_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(stemmer.stem(\"studying\"))\n",
        "print(lemmatizer.lemmatize(\"feet\"))\n",
        "print(lemmatizer.lemmatize(\"mice\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kc0DrE_Nbwo",
        "outputId": "2c1e5f6a-9a7e-46a2-82d5-8e849ee61889"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "studi\n",
            "foot\n",
            "mouse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stemmer.stem(\"car's\"))\n",
        "print(lemmatizer.lemmatize(\"car's\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlEDka0BN6uh",
        "outputId": "17985ab5-b0fe-476a-d5b6-e17ebf15430f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car'\n",
            "car's\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import nltk.stem as st"
      ],
      "metadata": {
        "id": "eFSLwR84PqxM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbClx7LvQJeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer1 = LancasterStemmer()\n",
        "print(stemmer1.stem(\"car's\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBpSpfF5P0_9",
        "outputId": "b9742813-c35f-4232-cc1b-7b4553fb8f28"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car's\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stemmer1.stem(\"studying\"))\n",
        "print(stemmer1.stem(\"studied\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGSnRrwEP8cw",
        "outputId": "5341203f-42ca-469c-fc42-3df34bf1e908"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "study\n",
            "study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemmatizer.lemmatize(\"are\", pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If5Rl9kAQeZ1",
        "outputId": "26612afe-4403-4584-f5a6-1c8e929f2a17"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-of-speech PoS"
      ],
      "metadata": {
        "id": "K-b6LZXjRA2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwy58cnJQnKG",
        "outputId": "d8a637ea-8113-4c75-f0f5-7933099892ca"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "QiKtqLPWRKrF"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(\" \".join(spamdf['v2'].array))\n",
        "print(len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BEELwXxRP9k",
        "outputId": "b2318f91-1087-4bb9-e686-a4ea6e983736"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71wbOr7SRZhk",
        "outputId": "3b2b4a6f-fd02-48dd-db03-dd4a69e6ea26"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Go until jurong point, crazy..',\n",
              " 'Available only in bugis n great world la e buffet... Cine there got amore wat... Ok lar...',\n",
              " 'Joking wif u oni... Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.',\n",
              " \"Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's U dun say so early hor... U c already then say... Nah I don't think he goes to usf, he lives around here though FreeMsg Hey there darling it's been 3 week's now and no word back!\",\n",
              " \"I'd like some fun you up for it still?\"]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "Gj3l6e41R5x0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(\" \".join(spamdf['v2'].array))\n",
        "print(len(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SuFtLzbSYoG",
        "outputId": "be9fe2de-c4ac-477e-c324-998b2d81d4f1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104144\n"
          ]
        }
      ]
    }
  ]
}